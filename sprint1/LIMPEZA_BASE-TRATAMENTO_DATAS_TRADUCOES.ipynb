{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "pd.set_option('display.width', 1000)\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn import metrics\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, roc_auc_score, f1_score, roc_curve, auc,precision_recall_curve\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan = pd.read_csv('loan.asc','delimiter',';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan['datetime'] = pd.to_datetime(loan['date'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-8dbbb8522cd4>:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  loan[['datetime']].describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1970-01-12 05:47:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>1970-01-11 18:31:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>1970-01-12 08:33:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime\n",
       "count                   682\n",
       "unique                  559\n",
       "top     1970-01-12 05:47:08\n",
       "freq                      4\n",
       "first   1970-01-11 18:31:45\n",
       "last    1970-01-12 08:33:28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan[['datetime']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _translate_and_clean(account,card,client,disp,district,loan,order,trans):\n",
    "    # Basic preprocessing / initial feature engineering:\n",
    "    # Translate from Czech to English, undo funny formats like for gender, add a few agg stats...\n",
    "\n",
    "    def num2date(x):\n",
    "        if isinstance(x, str):\n",
    "            return pd.to_datetime('19'+x, format='%Y%m%d %H:%M:%S')\n",
    "        else:\n",
    "            return pd.to_datetime(str(float(x)+19000000.), format='%Y%m%d')\n",
    "\n",
    "\n",
    "    # Account:\n",
    "    account['date'] = account['date'].apply(lambda x: num2date(x))\n",
    "    account['frequency'].replace('POPLATEK MESICNE','monthly',inplace=True)\n",
    "    account['frequency'].replace('POPLATEK TYDNE','weekly',inplace=True)\n",
    "    account['frequency'].replace('POPLATEK PO OBRATU','after_tr',inplace=True) # after transaction\n",
    "    account.rename(columns = {'frequency':'stmt_frq'}, inplace=True) # statement freq\n",
    "    # Card:\n",
    "    card['issued'] = card['issued'].apply(lambda x: num2date(x))\n",
    "    card.rename(columns = {'issued':'date'}, inplace=True) # date credit card issued\n",
    "    # Client:\n",
    "    client['MM']=client['birth_number']//100 - client['birth_number']//10000*100\n",
    "    client['gender'] = 'M'\n",
    "    client.loc[client['MM']>50,'gender'] = 'F'\n",
    "    client.loc[client['gender']=='F','birth_number'] -= 5000\n",
    "    client['birth_number'] = client['birth_number'].apply(lambda x: num2date(x))\n",
    "    client.rename(columns = {'birth_number':'date_birth'}, inplace=True) # client's birthdate\n",
    "    client.drop('MM',1,inplace=True)\n",
    "    # Disp:\n",
    "    disp['type'].replace('OWNER','owner',inplace=True)\n",
    "    disp['type'].replace('DISPONENT','disponent',inplace=True)\n",
    "    # District:\n",
    "    district.rename(columns = {\n",
    "    'A1':'district_id','A2':'dname','A3':'region','A4':'pop','A5':'nmu500','A6':'nmu2k',\n",
    "    'A7':'nmu10k','A8':'nmuinf','A9':'ncit','A10':'rurba','A11':'avgsal',\n",
    "    'A12':'urat95','A13':'urat96','A14':'ent_ppt','A15':'ncri95','A16':'ncri96'}, inplace=True)\n",
    "    # Loan:\n",
    "    loan['date'] = loan['date'].apply(lambda x: num2date(x))\n",
    "    # Order:\n",
    "    order['k_symbol'].replace('POJISTNE','ins_paymt',inplace=True) # insurrance payment\n",
    "    order['k_symbol'].replace('SIPO','household',inplace=True)\n",
    "    order['k_symbol'].replace('LEASING','leasing',inplace=True)\n",
    "    order['k_symbol'].replace('UVER','loan_payt',inplace=True) # loan payment\n",
    "    order.rename(columns = {'k_symbol':'category'}, inplace=True)\n",
    "    # Trans  # takes ~5min on my mbp w/ 16gb ram\n",
    "    trans['date'] = trans['date'].apply(lambda x: num2date(x))\n",
    "    trans['type'].replace('PRIJEM','credit',inplace=True)\n",
    "    trans['type'].replace('VYDAJ','withdrawal',inplace=True)\n",
    "    trans['operation'].replace('VYBER KARTOU','creditcard_wd',inplace=True) # credit card withdrawal\n",
    "    trans['operation'].replace('VKLAD','credit_in_cash',inplace=True)\n",
    "    trans['operation'].replace('PREVOD Z UCTU','coll_from_bank',inplace=True) # collection from another bank\n",
    "    trans['operation'].replace('VYBER','cash_wd',inplace=True) # cash withdrawal\n",
    "    trans['operation'].replace('PREVOD NA UCET','remi_to_bank',inplace=True) # remittance to another bank\n",
    "    trans['k_symbol'].replace('POJISTNE','ins_paymt',inplace=True) # insurrance payment\n",
    "    trans['k_symbol'].replace('SLUZBY','paymt_for_stmt',inplace=True) # payment for statement(?)\n",
    "    trans['k_symbol'].replace('UROK','int_credited',inplace=True) # interest credited\n",
    "    trans['k_symbol'].replace('SANKC. UROK','sanc_int',inplace=True) # sanction interest for neg balance\n",
    "    trans['k_symbol'].replace('SIPO','household',inplace=True)\n",
    "    trans['k_symbol'].replace('DUCHOD','pension',inplace=True) # old-age pension\n",
    "    trans['k_symbol'].replace('UVER','loan_paymt',inplace=True) # loan payment\n",
    "    trans.rename(columns = {'k_symbol':'category'}, inplace=True)\n",
    "    # Note the snafu that pandas int columns can't contain NaNs, but the\n",
    "    # trans.account (destination account#) field does, so it's type float.\n",
    "    # But account_id column is always filled so it's an integer.\n",
    "\n",
    "    return account,card,client,disp,district,loan,order,trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bank_data():\n",
    "    '''\n",
    "    Read, process, and provide the PKDD99 bank transactions data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    (none)\n",
    "    Returns\n",
    "    -------\n",
    "    account, card, client, disp, district, loan, order, trans : Pandas dataframe\n",
    "        The translated contents of the original PKDD99 dataset, contained in\n",
    "        Panads dataframes.  Further details are available in meta-data attached\n",
    "        to these dataframes in the .notes and .description attributes, e.g.\n",
    "        account.notes.  Additionally the loan dataframe has a meta-data\n",
    "        attribute of codes, i.e. loan.codes, returning the status definitions.\n",
    "        The rest of the details are in the dataset's original data description\n",
    "        document in the references.\n",
    "    Notes\n",
    "    -----\n",
    "    Assumes the files account.asc, card.asc, client.asc, disp.asc, district.asc,\n",
    "    loan.asc, order.asc, trans.asc from the original data distribution exist in\n",
    "    the current working directory.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pkdd99_bank_data as pkdd99\n",
    "    >>> account,card,client,disp,district,loan,order,trans = pkdd99.get_bank_data()\n",
    "    References\n",
    "    ----------\n",
    "    Original data description document with further info about fields/format:\n",
    "    http://sorry.vse.cz/~berka/challenge/pkdd1999/berka.htm\n",
    "    '''\n",
    "    # FIXME: ideally should have a check first that these files exist...\n",
    "    account = pd.read_csv('account.asc','delimiter',';')\n",
    "    card = pd.read_csv('card.asc','delimiter',';')\n",
    "    client = pd.read_csv('client.asc','delimiter',';')\n",
    "    disp = pd.read_csv('disp.asc','delimiter',';')\n",
    "    district = pd.read_csv('district.asc','delimiter',';')\n",
    "    loan = pd.read_csv('loan.asc','delimiter',';')\n",
    "    order = pd.read_csv('order.asc','delimiter',';')\n",
    "    trans = pd.read_csv('trans.asc','delimiter',';',low_memory=False)\n",
    "\n",
    "    account.name = 'Account'\n",
    "    card.name = 'Card'\n",
    "    client.name = 'Client'\n",
    "    disp.name = 'Disp'\n",
    "    district.name = 'District'\n",
    "    loan.name = 'Loan'\n",
    "    order.name = 'Order'\n",
    "    trans.name = 'Trans'\n",
    "\n",
    "    # descriptions are cut/pasted from the Financial Data Description webpage for the data\n",
    "    account.description = 'each record describes static characteristics of an account'\n",
    "    card.description = 'each record describes a credit card issued to an account'\n",
    "    client.description = 'each record describes characteristics of a client'\n",
    "    disp.description = 'each record relates together a client with an account'\n",
    "    district.description = 'each record describes demographic characteristics of a district'\n",
    "    loan.description = 'each record describes a loan granted for a given account'\n",
    "    order.description = 'each record describes characteristics of a payment order'\n",
    "    trans.description = 'each record describes one transaction on an account'\n",
    "\n",
    "    account.notes = '(one account can have one or more clients, e.g. married couples)'\n",
    "    card.notes = '(one account can have one or more credit cards)'\n",
    "    client.notes = '(one client can have one or more accounts)'\n",
    "    disp.notes = '(disposition connects a client/account pair and allows to link one or more cards)'\n",
    "    district.notes = '(neighborhoods for both bank/account branches and client homes.  same 16 fields as original A1-16.)'\n",
    "    loan.notes = '(one account may have zero or one loan.  see loan.codes for ABCD status definitions)'\n",
    "    order.notes = '(one payment order is from one account)'\n",
    "    trans.notes = '(category,bank,account are NaN for some types/operations.)'\n",
    "    loan.codes = 'Loan status codes:\\nA = contract finished, no problems\\nB = contract finished, loan not payed\\nC = running contract, OK so far\\nD = running contract, client in debt'\n",
    "\n",
    "    account,card,client,disp,district,loan,order,trans = _translate_and_clean(\n",
    "        account,card,client,disp,district,loan,order,trans\n",
    "    )\n",
    "\n",
    "    return account,card,client,disp,district,loan,order,trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "account,card,client,disp,district,loan,order, trans = get_bank_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "      <th>duration</th>\n",
       "      <th>payments</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5314</td>\n",
       "      <td>1787</td>\n",
       "      <td>1993-07-05</td>\n",
       "      <td>96396</td>\n",
       "      <td>12</td>\n",
       "      <td>8033.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5316</td>\n",
       "      <td>1801</td>\n",
       "      <td>1993-07-11</td>\n",
       "      <td>165960</td>\n",
       "      <td>36</td>\n",
       "      <td>4610.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6863</td>\n",
       "      <td>9188</td>\n",
       "      <td>1993-07-28</td>\n",
       "      <td>127080</td>\n",
       "      <td>60</td>\n",
       "      <td>2118.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5325</td>\n",
       "      <td>1843</td>\n",
       "      <td>1993-08-03</td>\n",
       "      <td>105804</td>\n",
       "      <td>36</td>\n",
       "      <td>2939.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7240</td>\n",
       "      <td>11013</td>\n",
       "      <td>1993-09-06</td>\n",
       "      <td>274740</td>\n",
       "      <td>60</td>\n",
       "      <td>4579.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_id  account_id       date  amount  duration  payments status\n",
       "0     5314        1787 1993-07-05   96396        12    8033.0      B\n",
       "1     5316        1801 1993-07-11  165960        36    4610.0      A\n",
       "2     6863        9188 1993-07-28  127080        60    2118.0      A\n",
       "3     5325        1843 1993-08-03  105804        36    2939.0      A\n",
       "4     7240       11013 1993-09-06  274740        60    4579.0      A"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>district_id</th>\n",
       "      <th>stmt_frq</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576</td>\n",
       "      <td>55</td>\n",
       "      <td>monthly</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3818</td>\n",
       "      <td>74</td>\n",
       "      <td>monthly</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704</td>\n",
       "      <td>55</td>\n",
       "      <td>monthly</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2378</td>\n",
       "      <td>16</td>\n",
       "      <td>monthly</td>\n",
       "      <td>1993-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2632</td>\n",
       "      <td>24</td>\n",
       "      <td>monthly</td>\n",
       "      <td>1993-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  district_id stmt_frq       date\n",
       "0         576           55  monthly 1993-01-01\n",
       "1        3818           74  monthly 1993-01-01\n",
       "2         704           55  monthly 1993-01-01\n",
       "3        2378           16  monthly 1993-01-01\n",
       "4        2632           24  monthly 1993-01-02"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan.to_csv('.//dados_tratados_usaveis//loan.csv', index=False, decimal=\".\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "account.to_csv('.//dados_tratados_usaveis//account.csv', index=False, decimal=\".\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_df_asc(tabela=str):\n",
    "    \"\"\"\n",
    "    Função para as bases de dados onde retorna no print o 'shape', um breve 'show' e o Scheema das variáveis.\n",
    "    :param entidade_name: string que referencie o nome da tabela que complete o caminho './original_data/{tabela}.asc'. \n",
    "    tabela pode ser => account, card, client, disp, district, loan, order \n",
    "    :return: DataFrame em pyspark\n",
    "    \"\"\"\n",
    "    df = spark.read.csv(path = f'./original_data/{tabela}.asc', header='True',inferSchema='False', sep=';')\n",
    "    print('\\n','A base de dados possui:',df.count(), 'linhas', 'e', len(df.columns), 'colunas', '\\n')\n",
    "    print(df.show(5))\n",
    "    print(df.printSchema())\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = read_df_asc('loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.session.timeZone\", \"Europe/Prague\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df1 = (\n",
    "    loan_df\n",
    "    .withColumn(\"date\", f.from_unixtime(\"date\"))\n",
    "    .withColumnRenamed(\"date\", \"date_loan\")\n",
    "    )\n",
    "loan_df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_df = read_df_asc('account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_df1 =(\n",
    "    account_df\n",
    "    .withColumn(\"date\", f.from_unixtime(\"date\"))\n",
    "    .withColumnRenamed(\"date\", \"date_account\")\n",
    ")\n",
    "account_df1.show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan and Account\n",
    "\n",
    "* 606 good loans and 76 bad\n",
    "* Features extracted:\n",
    "   - loan amount\n",
    "   - loan duration\n",
    "   - loan payment\n",
    "   - account district id\n",
    "   - frequency\n",
    "   - date loan issued\n",
    "   - date account opened\n",
    "   - days between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loan_df1.count())\n",
    "print(account_df1.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = account_df1.join(loan_df1, on=\"account_id\", how=\"inner\")\n",
    "df = df.withColumn(\"days_between\", f.datediff(\"date_loan\", \"date_account\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('days_between').summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição de bom e mau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good = df.filter((f.col(\"status\") == \"A\") | (f.col(\"status\") == \"C\"))\n",
    "df_bad = df.filter((f.col(\"status\") == \"B\") | (f.col(\"status\") == \"D\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_good.count())\n",
    "print(df_bad.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_loan'] = pd.to_datetime(df.date_loan, format='%Y-%m-%d')\n",
    "df['date_acc'] = pd.to_datetime(df.date_acc, format='%Y-%m-%d')\n",
    "df['days_between'] = df['date_loan'] - df['date_acc']\n",
    "df_good = df.loc[(df['status'] == 'A') | (df['status'] == 'C')]\n",
    "df_bad = df.loc[(df['status'] == 'B') | (df['status'] == 'D')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good_pd = df_good.toPandas()\n",
    "df_bad_pd = df_bad.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "df_good_pd.amount.hist(bins=20, ax=ax1, label='good', color='green', alpha=0.6)\n",
    "df_bad_pd.amount.hist(bins=20, ax=ax2, label='bad', color='red', alpha=0.6)\n",
    "ax1.set_title('Loan Amount')\n",
    "ax2.set_title('Loan Amount')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "df_good_pd.duration.hist(bins=20, ax=ax1, label='good', color='green', alpha=0.6)\n",
    "df_bad_pd.duration.hist(bins=20, ax=ax2, label='bad', color='red', alpha=0.6)\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payments\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "df_good_pd.payments.hist(bins=20, ax=ax1, label='good', color='green', alpha=0.6)\n",
    "df_bad_pd.payments.hist(bins=20, ax=ax2, label='bad', color='red', alpha=0.6)\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "df_good_pd[['account_id', 'frequency']].groupby('frequency').count().plot(kind='bar', color='green', rot=30, ax=ax1, alpha=0.6, legend=False)\n",
    "df_bad_pd[['account_id', 'frequency']].groupby('frequency').count().plot(kind='bar', color='red', rot=30, ax=ax2, alpha=0.6, legend=False)\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, regexp_extract\n",
    "\n",
    "\n",
    "titanic_df = titanic_df.withColumn(\"Initial\", regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
    "\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.select(\"Initial\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n",
    "               ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.select(\"Initial\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupby('Initial').avg('Age').collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "titanic_df.filter(col(\"Initial\") == 'Miss').select(\"Name\", \"Age\", \"Initial\").show(5)\n",
    "\n",
    "titanic_df.filter(titanic_df.Initial == 'Miss').select(\"Name\", \"Age\", \"Initial\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Miss\") & (titanic_df[\"Age\"].isNull()), 22).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Other\") & (titanic_df[\"Age\"].isNull()), 46).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Master\") & (titanic_df[\"Age\"].isNull()), 5).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mr\") & (titanic_df[\"Age\"].isNull()), 33).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mrs\") & (titanic_df[\"Age\"].isNull()), 36).otherwise(titanic_df[\"Age\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupBy(\"Embarked\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.na.fill({\"Embarked\" : 'S'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupBy(\"Embarked\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.describe(\"Cabin\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop(\"Cabin\")\n",
    "\n",
    "titanic_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn(\"Family_Size\",col('SibSp')+col('Parch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "titanic_df.groupBy(\"Family_Size\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "titanic_df.select(\"Name\", \"Family_Size\").orderBy(col(\"Family_Size\").desc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "titanic_df = titanic_df.withColumn('Alone',lit(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "\n",
    "titanic_df = titanic_df.withColumn('Alone',lit(0))\n",
    "titanic_df = titanic_df.withColumn(\"Alone\",when(titanic_df[\"Family_Size\"] == 0, 1).otherwise(titanic_df[\"Alone\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.codegen.wholeStage\", False)\n",
    "\n",
    "titanic_df.filter(titanic_df.Age > 70).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "\n",
    "titanic_df.orderBy(desc(\"age\")).show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "titanic_df.orderBy(asc(\"age\")).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.stat.corr(\"age\", \"fare\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.stat.corr(\"age\", \"family_size\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spark.apache.org/docs/latest/api/python//reference/pyspark.sql/api/pyspark.sql.DataFrameStatFunctions.html#pyspark.sql.DataFrameStatFunctions\n",
    "titanic_df.stat.crosstab(\"Embarked\", \"PClass\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupBy('pclass').agg({'fare': 'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDFs ajudam plugar funções complexas\n",
    "\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "\n",
    "def uppercase(str):\n",
    "    return str.upper()\n",
    "\n",
    "upperCaseUDF = udf(lambda z:uppercase(z),StringType())   \n",
    "\n",
    "titanic_df.select(upperCaseUDF(\"Name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f89240e11a62c0f9ffc54e01febbec25c1552bf38994777b0465512a43d202c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
